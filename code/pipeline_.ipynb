{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import time\n",
    "import json # For reading TR\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import pickle\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import os\n",
    "import wandb\n",
    "import random\n",
    "import math \n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from typing import List\n",
    "\n",
    "from transformers import AutoProcessor, AutoModel\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import project modules\n",
    "# import config # Import base config\n",
    "# from config import get_tr_from_json\n",
    "from data_loader import  load_fmri_data, load_video_data\n",
    "from evaluate import evaluate_model, plot_predictions\n",
    "from models import EncodingModel, DecodingModel, VoxelWiseEncodingModel # Using MLP models\n",
    "from models import LSTMEncodingModel, LSTMDecodingModel # Using LSTM models\n",
    "from preprocessing import preprocess_fmri, preprocess_video_embeddings, align_data\n",
    "from train import train_epoch # Import reverted train_epoch\n",
    "from video_encoder import VideoFeatureExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__) # Get logger instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup directories for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = Path(\"/workspace/hardik/\") # Adjusted path\n",
    "DATA_DIR = BASE_DIR / \"csai_data\" # Adjusted path\n",
    "\n",
    "OUTPUT_DIR = BASE_DIR / \"output_csai\"\n",
    "CACHE_DIR = BASE_DIR / \"cache_csai\"\n",
    "\n",
    "VIDEO_DIR = DATA_DIR / \"stimuli\"\n",
    "VIDEO_FILE_TEMPLATE = \"{stimulus_lower}.mp4\"\n",
    "\n",
    "OUTPUT_DIR.mkdir(exist_ok=True)\n",
    "CACHE_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SUBJECT_IDS = [\"NSD103\",\"NSD104\",\"NSD105\",\"NSD106\",\"NSD107\",\"NSD113\",\"NSD114\", \"NSD115\",\"NSD116\",\"NSD117\",\"NSD119\",\"NSD120\",\"NSD122\",\"NSD123\",\"NSD124\",\"NSD125\",\"NSD126\",\"NSD127\",\"NSD128\",\"NSD129\",\"NSD130\",\"NSD132\",\"NSD134\",\"NSD135\",\"NSD136\",\"NSD138\",\"NSD140\",\"NSD142\",\"NSD145\",\"NSD146\",\"NSD147\",\"NSD148\",\"NSD149\",\"NSD150\",\"NSD151\",\"NSD153\",\"NSD155\"] # List of subjects for training\n",
    "TEST_SUBJECT_IDS = [\"NSD108\",\"NSD109\",\"NSD110\",\"NSD111\"] # List of subjects for training\n",
    "TEST_SUBJECT_ID = \"NSD114\"     # Single subject for testing\n",
    "# STIMULI_NAMES = [\"iteration\", \"defeat\"]\n",
    "STIMULI_NAMES = [\"iteration\"]\n",
    "# STIMULI_NAMES = [\"growth\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- fMRI Parameters ---\n",
    "PREPROC_DIR = DATA_DIR / \"derivatives\" / \"preprocessed\"\n",
    "\n",
    "FMRI_VARIANT = \"nocensor_srm-recon\" \n",
    "FMRI_FILE_TEMPLATE = \"sub-{subject_id}_task-{stimulus_lower}_{variant}.nii.gz\"\n",
    "\n",
    "# Raw data directory template (string for formatting later)\n",
    "RAW_FUNC_DIR_PATH_TEMPLATE = DATA_DIR / \"sub-{subject_id}\" / \"func\"\n",
    "# Raw JSON template (string)\n",
    "RAW_JSON_FILENAME_TEMPLATE = \"sub-{subject_id}_task-{stimulus_lower}_echo-1_bold.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TR = 1 # Will be read dynamically\n",
    "\n",
    "TRS_DROP_MAP = {\n",
    "    \"growth\": (2, 11),\n",
    "    \"lemonade\": (2, 11),\n",
    "    \"iteration\": (2, 11),\n",
    "    \"defeat\": (2, 12),\n",
    "}\n",
    "\n",
    "# TRS_DROP_MAP = {\n",
    "#     \"iteration\": (2, 11)\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose the video encoder name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_ENCODER_NAME = 'vitmae' # timesformer, videomae, vivit, vitmae\n",
    "chosen_encoder = VIDEO_ENCODER_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIDEO_MODEL_IDENTIFIERS = {\n",
    "    'timesformer': \"facebook/timesformer-base-finetuned-k400\",\n",
    "    'videomae': \"MCG-NJU/videomae-base-finetuned-kinetics\",\n",
    "    # 'xclip': \"microsoft/xclip-base-patch32\",\n",
    "    'vivit' : \"google/vivit-b-16x2\",\n",
    "    \"vitmae\" : \"facebook/vit-mae-base\"\n",
    "}\n",
    "\n",
    "VIDEO_MODEL_OUTPUT_DIMS = {\n",
    "    'timesformer': 768,\n",
    "    'videomae': 768,\n",
    "    # 'xclip': 512,\n",
    "    'vivit' : 768,\n",
    "    'vitmae' :768 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder - these get overwritten at runtime based on VIDEO_ENCODER_NAME\n",
    "VIDEO_EMBEDDING_MODEL = VIDEO_MODEL_IDENTIFIERS[VIDEO_ENCODER_NAME]\n",
    "DEC_OUTPUT_DIM = VIDEO_MODEL_OUTPUT_DIMS[VIDEO_ENCODER_NAME]        # Will be set from VIDEO_MODEL_OUTPUT_DIMS\n",
    "\n",
    "# --- Video Processing Parameters  ---\n",
    "VIDEO_CHUNK_SIZE = 8 # Frames per model input clip (TimeSformer/VideoMAE usually 8 or 16)\n",
    "VIDEO_CHUNK_STRIDE = 4 # Overlap between chunks\n",
    "VIDEO_EMBEDDING_BATCH_SIZE = 4 # Reduce if OOM during *embedding extraction*\n",
    "\n",
    "# --- Preprocessing Parameters ---\n",
    "ALIGN_METHOD = \"convolve\"\n",
    "HRF_DELAY = 4.0\n",
    "\n",
    "DO_FMRI_ZSCORE = True\n",
    "DO_VIDEO_ZSCORE = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Model Parameters (MLP - Non-Temporal) ---\n",
    "USE_TEMPORAL_MODELS = False # Ensure this is False to use MLP\n",
    "DEVICE = \"cuda:2\" if torch.cuda.is_available() else \"cpu\"\n",
    "# --- MLP Hidden Dims ---\n",
    "ENC_HIDDEN_DIM = 512 # Hidden dim for MLP encoding model\n",
    "DEC_HIDDEN_DIM = 2048 # Hidden dim for MLP decoding model (reduced from 2048)\n",
    "# --- Input/Output Dims (set dynamically) ---\n",
    "ENC_OUTPUT_DIM = -1   # Set dynamically (PCA components)\n",
    "DEC_INPUT_DIM = -1    # Set dynamically (PCA components)\n",
    "\n",
    "APPLY_PCA = True # Flag to enable/disable PCA\n",
    "PCA_N_COMPONENTS = 1000 # Target number of fMRI features after PCA\n",
    "\n",
    "# --- Training Parameters ---\n",
    "LEARNING_RATE = 1e-5\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 50\n",
    "\n",
    "# --- Evaluation ---\n",
    "EVAL_METRICS = ['mse', 'pearsonr', 'r2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Video Encoder: vitmae (ID: facebook/vit-mae-base, Dim: 768)\n",
      "Train Subject(s): ['NSD103', 'NSD104', 'NSD105', 'NSD106', 'NSD107', 'NSD113', 'NSD114', 'NSD115', 'NSD116', 'NSD117', 'NSD119', 'NSD120', 'NSD122', 'NSD123', 'NSD124', 'NSD125', 'NSD126', 'NSD127', 'NSD128', 'NSD129', 'NSD130', 'NSD132', 'NSD134', 'NSD135', 'NSD136', 'NSD138', 'NSD140', 'NSD142', 'NSD145', 'NSD146', 'NSD147', 'NSD148', 'NSD149', 'NSD150', 'NSD151', 'NSD153', 'NSD155'], Test Subject: NSD114\n",
      "Device: cuda:2, fMRI Variant: nocensor_srm-recon\n",
      "Apply PCA: True, PCA Components: 1000\n",
      "Using Temporal Models: False\n"
     ]
    }
   ],
   "source": [
    "print(f\"Selected Video Encoder: {chosen_encoder} (ID: {VIDEO_EMBEDDING_MODEL}, Dim: {DEC_OUTPUT_DIM})\")\n",
    "\n",
    "# --- Log Core Config ---\n",
    "print(f\"Train Subject(s): {TRAIN_SUBJECT_IDS}, Test Subject: {TEST_SUBJECT_ID}\")\n",
    "print(f\"Device: {DEVICE}, fMRI Variant: {FMRI_VARIANT}\")\n",
    "print(f\"Apply PCA: {APPLY_PCA}, PCA Components: {PCA_N_COMPONENTS if APPLY_PCA else 'N/A'}\")\n",
    "print(f\"Using Temporal Models: {USE_TEMPORAL_MODELS}\") # Should be False for MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "fmri_tr = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup class to provide video embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_extractor = VideoFeatureExtractor(\n",
    "    model_id=VIDEO_EMBEDDING_MODEL,\n",
    "    fps=23.98,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data, filename: Path):\n",
    "    logger.info(f\"Saving data to {filename}\")\n",
    "    filename.parent.mkdir(parents=True, exist_ok=True) # Ensure directory exists\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_data(filename: Path):\n",
    "    logger.info(f\"Loading data from {filename}\")\n",
    "    if not filename.exists():\n",
    "        logger.error(f\"Cache file not found: {filename}\")\n",
    "        return None\n",
    "    try:\n",
    "        with open(filename, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error loading cache file {filename}: {e}\", exc_info=True)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_subject_data(subject_id, fmri_tr, chosen_encoder):\n",
    "    \"\"\"Loads, preprocesses, and aligns data for a single subject.\"\"\"\n",
    "    \n",
    "    print(f\"--- Processing data for Subject: {subject_id} ---\")\n",
    "    subject_fmri_aligned = []\n",
    "    subject_video_aligned = []\n",
    "    \n",
    "    # find the model output dimensions from the dictionary defined above\n",
    "    expected_vid_dim = VIDEO_MODEL_OUTPUT_DIMS[chosen_encoder]\n",
    "    safe_encoder_name = chosen_encoder.replace('/','_') # Safe name for filenames\n",
    "\n",
    "    video_embeddings_cache = {} # Cache loaded video embeddings per stimulus\n",
    "\n",
    "    # Include PCA components in cache filename\n",
    "    pca_suffix = f\"_pca{PCA_N_COMPONENTS}\" if APPLY_PCA else \"\"\n",
    "\n",
    "    for stimulus_lower in STIMULI_NAMES:\n",
    "        print(f\"Processing {subject_id} / {stimulus_lower}...\")\n",
    "        # --- Define file paths ---\n",
    "        fmri_filename = FMRI_FILE_TEMPLATE.format(\n",
    "            subject_id=subject_id,\n",
    "            stimulus_lower=stimulus_lower,\n",
    "            variant=FMRI_VARIANT\n",
    "        )\n",
    "        fmri_path = PREPROC_DIR / f\"sub-{subject_id}\" / fmri_filename\n",
    "        video_filename = VIDEO_FILE_TEMPLATE.format(stimulus_lower=stimulus_lower)\n",
    "        video_path = VIDEO_DIR / video_filename\n",
    "\n",
    "        # --- Cache Keys ---\n",
    "        aligned_cache_key = f\"sub-{subject_id}_{stimulus_lower}_{FMRI_VARIANT}_{safe_encoder_name}{pca_suffix}_aligned.pkl\"\n",
    "        aligned_cache_file = CACHE_DIR / aligned_cache_key\n",
    "        \n",
    "        # Video embeddings are stimulus-specific, cache key doesn't need subject_id\n",
    "        embedding_cache_key = f\"{stimulus_lower}_{safe_encoder_name}_embeddings.npy\"\n",
    "        embedding_cache_file = CACHE_DIR / embedding_cache_key\n",
    "\n",
    "        # --- Check cache for ALIGNED data first ---\n",
    "        if aligned_cache_file.exists():\n",
    "            cached_data = load_data(aligned_cache_file)\n",
    "            if cached_data:\n",
    "                fmri_aligned, video_aligned = cached_data\n",
    "                if fmri_aligned.ndim == 2 and video_aligned.ndim == 2 and \\\n",
    "                   fmri_aligned.shape[0] == video_aligned.shape[0] and \\\n",
    "                   video_aligned.shape[1] == expected_vid_dim:\n",
    "                    subject_fmri_aligned.append(fmri_aligned)\n",
    "                    subject_video_aligned.append(video_aligned)\n",
    "                    print(f\"Loaded cached aligned data for {subject_id}/{stimulus_lower}\")\n",
    "                    continue # Go to next stimulus if aligned cache is valid\n",
    "                else:\n",
    "                    print(f\"-> Invalid cached aligned data shape/dim for {subject_id}/{stimulus_lower}. Recomputing.\")\n",
    "\n",
    "\n",
    "        # --- Load Raw fMRI Data ---\n",
    "        try:\n",
    "            start_load = time.time()\n",
    "            print(f\"Loading fMRI from: {fmri_path}\")\n",
    "            fmri_data = load_fmri_data(fmri_path, stimulus_lower, fmri_tr, FMRI_VARIANT, TRS_DROP_MAP)\n",
    "            if fmri_data is None or fmri_data.size == 0:\n",
    "                 print(f\"-> fMRI data loading failed or resulted in empty array for {subject_id}/{stimulus_lower}.\")\n",
    "                 continue # Skip this stimulus\n",
    "            print(f\"fMRI loaded in {time.time() - start_load:.2f}s. Shape: {fmri_data.shape}\")\n",
    "        except FileNotFoundError:\n",
    "            print(f\"-> fMRI file not found for {subject_id}/{stimulus_lower}: {fmri_path}. Skipping stimulus.\")\n",
    "            continue\n",
    "\n",
    "\n",
    "        # --- Load/Cache Video Embeddings (Stimulus Specific) ---\n",
    "        video_embeddings = None\n",
    "        if stimulus_lower in video_embeddings_cache:\n",
    "            video_embeddings = video_embeddings_cache[stimulus_lower]\n",
    "            print(f\"Using pre-loaded video embeddings for {stimulus_lower}.\")\n",
    "        elif embedding_cache_file.exists():\n",
    "            print(f\"Loading cached {chosen_encoder} video embeddings from: {embedding_cache_file}\")\n",
    "            video_embeddings = np.load(embedding_cache_file)\n",
    "            if video_embeddings.ndim != 2 or video_embeddings.shape[1] != expected_vid_dim:\n",
    "                print(f\"-> Cached embeddings {embedding_cache_file} have wrong shape/dim ({video_embeddings.shape}). Re-extracting.\")\n",
    "                embedding_cache_file.unlink()\n",
    "                video_embeddings = None\n",
    "            else:\n",
    "                video_embeddings_cache[stimulus_lower] = video_embeddings # Store in memory cache\n",
    "        else:\n",
    "            video_embeddings = None # Needs extraction\n",
    "\n",
    "        # --- Extract Video Embeddings if needed ---\n",
    "        video_frames, video_fps_load_check = load_video_data(video_path) # Get FPS here too\n",
    "        video_extractor = VideoFeatureExtractor(\n",
    "        model_id=VIDEO_EMBEDDING_MODEL,\n",
    "        fps=video_fps_load_check,\n",
    "        device=DEVICE\n",
    "        )\n",
    "        if video_embeddings is None:\n",
    "            try:\n",
    "                # Load video frames (only if extraction is needed)\n",
    "                print(f\"Loading video frames from: {video_path}\")\n",
    "                start_vid_load = time.time()\n",
    "                if not video_frames:\n",
    "                     logger.error(f\"Failed to load video frames for {stimulus_lower}. Skipping.\")\n",
    "                     continue\n",
    "                print(f\"Video frames loaded in {time.time() - start_vid_load:.2f}s.\")\n",
    "\n",
    "                print(f\"Extracting {chosen_encoder} video embeddings for {stimulus_lower}...\")\n",
    "                start_embed = time.time()\n",
    "                video_embeddings = video_extractor.extract_features(video_frames, batch_size=VIDEO_EMBEDDING_BATCH_SIZE)\n",
    "                print(f\"Video embedding shape : {video_embeddings.shape}\")\n",
    "                print(f\"Video embedding extraction took {time.time() - start_embed:.2f}s\")\n",
    "\n",
    "                if video_embeddings is None or video_embeddings.size == 0: raise ValueError(\"Extractor returned empty embeddings\")\n",
    "\n",
    "                if video_embeddings.shape[1] != expected_vid_dim:\n",
    "                     logger.error(f\"Extracted {chosen_encoder} dim {video_embeddings.shape[1]} != expected {expected_vid_dim}.\")\n",
    "                     continue # Skip if extraction yields wrong dimension\n",
    "\n",
    "                np.save(embedding_cache_file, video_embeddings)\n",
    "                print(f\"Saved {chosen_encoder} video embeddings to: {embedding_cache_file}\")\n",
    "                video_embeddings_cache[stimulus_lower] = video_embeddings # Store in memory cache\n",
    "                # Need video_fps for alignment, get it from the load_video_data call\n",
    "                video_fps = video_fps_load_check\n",
    "                num_video_frames_original = len(video_frames)\n",
    "\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Video embedding extraction failed for {stimulus_lower} / {chosen_encoder}: {e}\", exc_info=True)\n",
    "                continue\n",
    "\n",
    "        else:\n",
    "             # If embeddings loaded from cache, we still need FPS and frame count for alignment\n",
    "             # Re-load video just to get metadata if not already loaded \n",
    "             \n",
    "             try:\n",
    "                 # Quick load just for metadata\n",
    "                 _ , video_fps_check = load_video_data(video_path)\n",
    "                 # Assuming frame count isn't strictly needed if embeddings exist, but FPS is\n",
    "                 video_fps = video_fps_check\n",
    "\n",
    "                 # [TODO]\n",
    "                 # We don't have exact num_frames_original if only cache was loaded,\n",
    "                 # but maybe it's not strictly needed by align_data if using chunk times? Check align_data.\n",
    "                 # For safety, let's pass 0 or estimate if needed by align_data.\n",
    "                 # Revisit align_data's use of num_video_frames_original. If it's just for logging, it's ok.\n",
    "\n",
    "                 num_video_frames_original = 0 # Placeholder if only cache loaded\n",
    "                 \n",
    "             except Exception as e:\n",
    "                  logger.error(f\"Could not load video metadata for {video_path} even though embeddings exist: {e}. Skipping alignment.\")\n",
    "                  continue\n",
    "\n",
    "\n",
    "        # --- Preprocess & Align ---\n",
    "        try:\n",
    "            start_preprocess = time.time()\n",
    "            fmri_processed = preprocess_fmri(DO_FMRI_ZSCORE, APPLY_PCA, PCA_N_COMPONENTS,  fmri_data)\n",
    "            video_embeddings_processed = preprocess_video_embeddings(DO_VIDEO_ZSCORE, video_embeddings)\n",
    "            fmri_aligned, video_aligned = align_data(\n",
    "                fmri_processed,\n",
    "                video_embeddings_processed,\n",
    "                fmri_tr=fmri_tr,\n",
    "                video_fps=video_fps, # Use FPS obtained above\n",
    "                num_video_frames_original=num_video_frames_original, # Use value obtained above\n",
    "                hrf_delay=HRF_DELAY,\n",
    "                align_method=ALIGN_METHOD,\n",
    "                video_chunk_size=video_extractor.num_frames_per_clip,\n",
    "                video_chunk_stride=VIDEO_CHUNK_STRIDE\n",
    "            )\n",
    "            print(f\"Preprocessing and alignment took {time.time() - start_preprocess:.2f}s\")\n",
    "            if fmri_aligned.shape[0] == 0 or video_aligned.shape[0] == 0:\n",
    "                print(f\"-> Alignment resulted in empty data for {subject_id}/{stimulus_lower}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            save_data((fmri_aligned, video_aligned), aligned_cache_file) # Save to subject specific cache\n",
    "            subject_fmri_aligned.append(fmri_aligned)\n",
    "            subject_video_aligned.append(video_aligned)\n",
    "\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during preprocess/align for {subject_id}/{stimulus_lower}: {e}\", exc_info=True)\n",
    "            continue\n",
    "        # --- End Stimulus Loop ---\n",
    "\n",
    "    # --- Concatenate data for *this* subject ---\n",
    "    if not subject_fmri_aligned:\n",
    "        print(f\"-> No data successfully processed for subject {subject_id}.\")\n",
    "        return None, None # Return None if no data for this subject\n",
    "\n",
    "    final_fmri = np.concatenate(subject_fmri_aligned, axis=0)\n",
    "    final_video = np.concatenate(subject_video_aligned, axis=0)\n",
    "    print(f\"--- Final Concatenated Data Shapes for Subject {subject_id} ---\")\n",
    "    print(f\"Subject fMRI data: {final_fmri.shape}\")\n",
    "    print(f\"Subject Video embeddings: {final_video.shape}\")\n",
    "    return final_fmri, final_video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing data for Subject: NSD103 ---\n",
      "Processing NSD103 / iteration...\n",
      "Loaded cached aligned data for NSD103/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD103 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD104 ---\n",
      "Processing NSD104 / iteration...\n",
      "Loaded cached aligned data for NSD104/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD104 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD105 ---\n",
      "Processing NSD105 / iteration...\n",
      "Loaded cached aligned data for NSD105/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD105 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD106 ---\n",
      "Processing NSD106 / iteration...\n",
      "Loaded cached aligned data for NSD106/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD106 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD107 ---\n",
      "Processing NSD107 / iteration...\n",
      "Loaded cached aligned data for NSD107/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD107 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD113 ---\n",
      "Processing NSD113 / iteration...\n",
      "Loaded cached aligned data for NSD113/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD113 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD114 ---\n",
      "Processing NSD114 / iteration...\n",
      "Loaded cached aligned data for NSD114/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD114 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD115 ---\n",
      "Processing NSD115 / iteration...\n",
      "Loaded cached aligned data for NSD115/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD115 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD116 ---\n",
      "Processing NSD116 / iteration...\n",
      "Loaded cached aligned data for NSD116/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD116 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD117 ---\n",
      "Processing NSD117 / iteration...\n",
      "Loaded cached aligned data for NSD117/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD117 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD119 ---\n",
      "Processing NSD119 / iteration...\n",
      "Loaded cached aligned data for NSD119/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD119 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD120 ---\n",
      "Processing NSD120 / iteration...\n",
      "Loaded cached aligned data for NSD120/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD120 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD122 ---\n",
      "Processing NSD122 / iteration...\n",
      "Loaded cached aligned data for NSD122/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD122 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD123 ---\n",
      "Processing NSD123 / iteration...\n",
      "Loaded cached aligned data for NSD123/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD123 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD124 ---\n",
      "Processing NSD124 / iteration...\n",
      "Loaded cached aligned data for NSD124/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD124 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD125 ---\n",
      "Processing NSD125 / iteration...\n",
      "Loaded cached aligned data for NSD125/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD125 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD126 ---\n",
      "Processing NSD126 / iteration...\n",
      "Loaded cached aligned data for NSD126/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD126 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD127 ---\n",
      "Processing NSD127 / iteration...\n",
      "Loaded cached aligned data for NSD127/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD127 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD128 ---\n",
      "Processing NSD128 / iteration...\n",
      "Loaded cached aligned data for NSD128/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD128 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD129 ---\n",
      "Processing NSD129 / iteration...\n",
      "Loaded cached aligned data for NSD129/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD129 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD130 ---\n",
      "Processing NSD130 / iteration...\n",
      "Loaded cached aligned data for NSD130/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD130 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD132 ---\n",
      "Processing NSD132 / iteration...\n",
      "Loaded cached aligned data for NSD132/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD132 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD134 ---\n",
      "Processing NSD134 / iteration...\n",
      "Loaded cached aligned data for NSD134/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD134 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD135 ---\n",
      "Processing NSD135 / iteration...\n",
      "Loaded cached aligned data for NSD135/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD135 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD136 ---\n",
      "Processing NSD136 / iteration...\n",
      "Loaded cached aligned data for NSD136/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD136 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD138 ---\n",
      "Processing NSD138 / iteration...\n",
      "Loaded cached aligned data for NSD138/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD138 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD140 ---\n",
      "Processing NSD140 / iteration...\n",
      "Loaded cached aligned data for NSD140/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD140 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD142 ---\n",
      "Processing NSD142 / iteration...\n",
      "Loaded cached aligned data for NSD142/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD142 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD145 ---\n",
      "Processing NSD145 / iteration...\n",
      "Loaded cached aligned data for NSD145/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD145 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD146 ---\n",
      "Processing NSD146 / iteration...\n",
      "Loaded cached aligned data for NSD146/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD146 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD147 ---\n",
      "Processing NSD147 / iteration...\n",
      "Loaded cached aligned data for NSD147/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD147 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD148 ---\n",
      "Processing NSD148 / iteration...\n",
      "Loaded cached aligned data for NSD148/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD148 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD149 ---\n",
      "Processing NSD149 / iteration...\n",
      "Loaded cached aligned data for NSD149/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD149 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD150 ---\n",
      "Processing NSD150 / iteration...\n",
      "Loaded cached aligned data for NSD150/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD150 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD151 ---\n",
      "Processing NSD151 / iteration...\n",
      "Loaded cached aligned data for NSD151/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD151 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD153 ---\n",
      "Processing NSD153 / iteration...\n",
      "Loaded cached aligned data for NSD153/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD153 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD155 ---\n",
      "Processing NSD155 / iteration...\n",
      "Loaded cached aligned data for NSD155/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD155 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n"
     ]
    }
   ],
   "source": [
    "all_train_fmri_raw = []\n",
    "all_train_video = []\n",
    "for train_subj_id in TRAIN_SUBJECT_IDS:\n",
    "    fmri_subj_raw, video_subj = process_subject_data(train_subj_id, fmri_tr, chosen_encoder)\n",
    "    \n",
    "    if fmri_subj_raw is not None and video_subj is not None:\n",
    "        all_train_fmri_raw.append(fmri_subj_raw)\n",
    "        all_train_video.append(video_subj)\n",
    "    else:\n",
    "        logger.warning(f\"Could not process data for training subject: {train_subj_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Combined Training Data Shapes (Before PCA) ---\n",
      "Train fMRI (Raw/SRM): (27454, 1000)\n",
      "Train Video (vitmae): (27454, 768)\n"
     ]
    }
   ],
   "source": [
    "final_train_fmri = np.concatenate(all_train_fmri_raw, axis=0)\n",
    "final_train_video = np.concatenate(all_train_video, axis=0)\n",
    "print(f\"--- Combined Training Data Shapes (Before PCA) ---\")\n",
    "print(f\"Train fMRI (Raw/SRM): {final_train_fmri.shape}\")\n",
    "print(f\"Train Video ({chosen_encoder}): {final_train_video.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Prepare Training DataLoader ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train DataLoader ready (Size: 429 samples).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_dataset = TensorDataset(torch.from_numpy(final_train_fmri).float(),\n",
    "                                    torch.from_numpy(final_train_video).float())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    print(f\"Train DataLoader ready (Size: {len(train_loader)} samples).\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create training DataLoader: {e}\", exc_info=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing the Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Process Test Data ---\n",
    "final_test_fmri = None\n",
    "video_test = None\n",
    "test_loader = None\n",
    "test_dataset = None\n",
    "\n",
    "# if TEST_SUBJECT_ID:\n",
    "#     print(f\"--- Processing Test Data for Subject: {TEST_SUBJECT_ID} ---\")\n",
    "#     final_test_fmri, video_test = process_subject_data(TEST_SUBJECT_ID, fmri_tr, chosen_encoder)\n",
    "#     print(final_test_fmri.shape, video_test.shape)\n",
    "\n",
    "#     if final_test_fmri is None or video_test is None:\n",
    "#         print(f\"No test data could be processed for subject {TEST_SUBJECT_ID}. Cannot evaluate.\")\n",
    "#         # Decide whether to proceed with training only or exit\n",
    "#     else:\n",
    "#         print(f\"--- Final Test Data Shapes (After PCA if Applied) ---\")\n",
    "#         print(f\"Test fMRI data: {final_test_fmri.shape}\")\n",
    "#         print(f\"Test Video embeddings: {video_test.shape}\")\n",
    "\n",
    "#         # --- Prepare Test DataLoader ---\n",
    "#         try:\n",
    "#             test_dataset = TensorDataset(torch.from_numpy(final_test_fmri).float(),\n",
    "#                                             torch.from_numpy(video_test).float())\n",
    "#             test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, pin_memory=True)\n",
    "#             print(f\"Test Dataset ready (Size: {len(test_dataset)} samples).\")\n",
    "#             print(f\"Test DataLoader ready (Size: {len(test_loader)} samples).\")\n",
    "#         except Exception as e:\n",
    "#                 logger.error(f\"Failed to create test DataLoader: {e}\", exc_info=True)\n",
    "#                 test_loader = None # Mark as None if failed\n",
    "# else:\n",
    "#         print(\"No TEST_SUBJECT_ID specified. Skipping test phase.\")\n",
    "#         test_loader = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing data for Subject: NSD108 ---\n",
      "Processing NSD108 / iteration...\n",
      "Loaded cached aligned data for NSD108/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD108 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD109 ---\n",
      "Processing NSD109 / iteration...\n",
      "Loaded cached aligned data for NSD109/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD109 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD110 ---\n",
      "Processing NSD110 / iteration...\n",
      "Loaded cached aligned data for NSD110/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD110 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n",
      "--- Processing data for Subject: NSD111 ---\n",
      "Processing NSD111 / iteration...\n",
      "Loaded cached aligned data for NSD111/iteration\n",
      "--- Final Concatenated Data Shapes for Subject NSD111 ---\n",
      "Subject fMRI data: (742, 1000)\n",
      "Subject Video embeddings: (742, 768)\n"
     ]
    }
   ],
   "source": [
    "all_test_fmri_raw = []\n",
    "all_test_video = []\n",
    "for test_subj_id in TEST_SUBJECT_IDS:\n",
    "    fmri_subj_raw, video_subj = process_subject_data(test_subj_id, fmri_tr, chosen_encoder)\n",
    "    \n",
    "    if fmri_subj_raw is not None and video_subj is not None:\n",
    "        all_test_fmri_raw.append(fmri_subj_raw)\n",
    "        all_test_video.append(video_subj)\n",
    "    else:\n",
    "        logger.warning(f\"Could not process data for testing subject: {test_subj_id}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Combined Testing Data Shapes (Before PCA) ---\n",
      "Test fMRI (Raw/SRM): (2968, 1000)\n",
      "Test Video (vitmae): (2968, 768)\n"
     ]
    }
   ],
   "source": [
    "final_test_fmri = np.concatenate(all_test_fmri_raw, axis=0)\n",
    "final_test_video = np.concatenate(all_test_video, axis=0)\n",
    "print(f\"--- Combined Testing Data Shapes (Before PCA) ---\")\n",
    "print(f\"Test fMRI (Raw/SRM): {final_test_fmri.shape}\")\n",
    "print(f\"Test Video ({chosen_encoder}): {final_test_video.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test DataLoader ready (Size: 47 samples).\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    test_dataset = TensorDataset(torch.from_numpy(final_test_fmri).float(),\n",
    "                                    torch.from_numpy(final_test_video).float())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    print(f\"Test DataLoader ready (Size: {len(test_loader)} samples).\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to create test DataLoader: {e}\", exc_info=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Update config dims (Based on final *training* data) ---\n",
    "ENC_OUTPUT_DIM = final_train_fmri.shape[1]\n",
    "DEC_INPUT_DIM = final_train_fmri.shape[1]\n",
    "\n",
    "# DEC_OUTPUT_DIM is already set based on video encoder choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_model = EncodingModel(\n",
    "    video_embed_dim=DEC_OUTPUT_DIM,\n",
    "    fmri_dim=ENC_OUTPUT_DIM,\n",
    "    hidden_dim=ENC_HIDDEN_DIM\n",
    ")\n",
    "decoding_model = DecodingModel(\n",
    "    fmri_dim=DEC_INPUT_DIM,\n",
    "    video_embed_dim=DEC_OUTPUT_DIM,\n",
    "    hidden_dim=DEC_HIDDEN_DIM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training_no_val(model, train_loader, device, task='encoding', epochs=EPOCHS\n",
    "                        , learning_rate=LEARNING_RATE):\n",
    "    \"\"\" Simplified training loop without validation. \"\"\"\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    np.random.seed(42)\n",
    "    random.seed(42)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "    model_type = \"LSTM\" if USE_TEMPORAL_MODELS else \"VoxelWiseMLP\"\n",
    "    \n",
    "    if model_type == \"LSTM\" and task == 'encoding':\n",
    "        model =  LSTMEncodingModel(\n",
    "            video_embed_dim=DEC_OUTPUT_DIM,\n",
    "            fmri_dim=ENC_OUTPUT_DIM,\n",
    "            hidden_dim=ENC_HIDDEN_DIM\n",
    "        )\n",
    "    elif model_type == \"LSTM\" and task == 'decoding':\n",
    "        model = LSTMDecodingModel(\n",
    "            fmri_dim=DEC_INPUT_DIM,\n",
    "            video_embed_dim=DEC_OUTPUT_DIM,\n",
    "            hidden_dim=DEC_HIDDEN_DIM\n",
    "        )\n",
    "    elif model_type == \"VoxelWiseMLP\" and task == 'encoding':\n",
    "        model = VoxelWiseEncodingModel(\n",
    "            video_embed_dim=DEC_OUTPUT_DIM,\n",
    "            fmri_dim=ENC_OUTPUT_DIM,\n",
    "            hidden_dim=ENC_HIDDEN_DIM\n",
    "        )\n",
    "    else:\n",
    "        model = DecodingModel(\n",
    "            fmri_dim=DEC_INPUT_DIM,\n",
    "            video_embed_dim=DEC_OUTPUT_DIM,\n",
    "            hidden_dim=DEC_HIDDEN_DIM\n",
    "        )\n",
    "    \n",
    "\n",
    "    print(f\"Starting {task} model training ({model_type}, no validation) for {epochs} epochs on {device}\")\n",
    "    model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    stimuli_str = \"_\".join(STIMULI_NAMES)\n",
    "\n",
    "    run = f\"{task}_{model_type}_{VIDEO_ENCODER_NAME}_{PCA_N_COMPONENTS if APPLY_PCA else 'nopca'}_{stimuli_str}\"\n",
    "    config = {\n",
    "        \"task\": task,\n",
    "        \"model_type\": model_type,\n",
    "        \"video_encoder\": VIDEO_ENCODER_NAME,\n",
    "        \"pca_components\": PCA_N_COMPONENTS if APPLY_PCA else \"nopca\",\n",
    "        \"stimuli\": stimuli_str,\n",
    "        \"learning_rate\": learning_rate,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"epochs\": epochs,\n",
    "        \"encoder_hidden_dim\": ENC_HIDDEN_DIM,\n",
    "        \"decoder_hidden_dim\": DEC_HIDDEN_DIM,\n",
    "        \"encoder_output_dim\": ENC_OUTPUT_DIM,\n",
    "        \"decoder_input_dim\": DEC_INPUT_DIM,\n",
    "        \"decoder_output_dim\": DEC_OUTPUT_DIM,\n",
    "        \"train_subjects\": TRAIN_SUBJECT_IDS,\n",
    "        \"test_subject\": TEST_SUBJECT_ID,\n",
    "    }\n",
    "    wandb.init(project=\"csai_fmri_video_project\", name=run, config=config, reinit=True) # Initialize wandb\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Pass use_temporal flag if train_epoch still expects it, otherwise remove\n",
    "        train_loss = train_epoch(model, train_loader, criterion, optimizer, device, task)\n",
    "        print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f}\")\n",
    "        # No validation step, no saving best model based on validation\n",
    "        print(\"> Evaluation on train\")\n",
    "        results, _, _ = evaluate_model(model, train_loader, nn.MSELoss(), device=DEVICE, task=task)\n",
    "               \n",
    "        print(\"\\n> Evaluation on test\")\n",
    "        test_results, _, _ = evaluate_model(model, test_loader, nn.MSELoss(), device=DEVICE, task=task)\n",
    "        wandb.log({\n",
    "                \"MSE\": results['mse'], \n",
    "                \"PearsonR Avg\": results['pearsonr_avg'],\n",
    "                \"PearsonR All\": np.median(results['pearsonr_all']),\n",
    "                \"R2 Uniform\": results['r2_uniform'],\n",
    "                \"R2 Variance\": results['r2_variance'],\n",
    "                \"Test MSE\": test_results['mse'],\n",
    "                \"Test PearsonR Avg\": test_results['pearsonr_avg'],\n",
    "                \"Test PearsonR All\": np.median(test_results['pearsonr_all']),\n",
    "                \"Test R2 Uniform\": test_results['r2_uniform'],\n",
    "                \"Test R2 Variance\": test_results['r2_variance']\n",
    "            })\n",
    "\n",
    "    print(f\"Training complete after {epochs} epochs. Using model from last epoch.\")\n",
    "    wandb.finish() # Finish wandb run\n",
    "    return model # Return model from last epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting encoding model training (VoxelWiseMLP, no validation) for 50 epochs on cuda:2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmhardik003\u001b[0m (\u001b[33mwb-team-hardik\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Using a boolean value for 'reinit' is deprecated. Use 'return_previous' or 'finish_previous' instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/hardik/csai_project/final/wandb/run-20250509_104929-id3eznbd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wb-team-hardik/csai_fmri_video_project/runs/id3eznbd' target=\"_blank\">encoding_VoxelWiseMLP_vitmae_1000_iteration</a></strong> to <a href='https://wandb.ai/wb-team-hardik/csai_fmri_video_project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wb-team-hardik/csai_fmri_video_project' target=\"_blank\">https://wandb.ai/wb-team-hardik/csai_fmri_video_project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wb-team-hardik/csai_fmri_video_project/runs/id3eznbd' target=\"_blank\">https://wandb.ai/wb-team-hardik/csai_fmri_video_project/runs/id3eznbd</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 0.9997\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9885\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1055\n",
      "  Median Pearson Correlation: 0.1049\n",
      "  R2 Score (uniform avg): 0.0099\n",
      "  R2 Score (variance weighted): 0.0099\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0007\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0263\n",
      "  Median Pearson Correlation: 0.0254\n",
      "  R2 Score (uniform avg): -0.0015\n",
      "  R2 Score (variance weighted): -0.0015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.9904\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9821\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1369\n",
      "  Median Pearson Correlation: 0.1362\n",
      "  R2 Score (uniform avg): 0.0163\n",
      "  R2 Score (variance weighted): 0.0163\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0011\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0350\n",
      "  Median Pearson Correlation: 0.0340\n",
      "  R2 Score (uniform avg): -0.0019\n",
      "  R2 Score (variance weighted): -0.0019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.9854\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9778\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1528\n",
      "  Median Pearson Correlation: 0.1522\n",
      "  R2 Score (uniform avg): 0.0207\n",
      "  R2 Score (variance weighted): 0.0207\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0016\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0404\n",
      "  Median Pearson Correlation: 0.0402\n",
      "  R2 Score (uniform avg): -0.0023\n",
      "  R2 Score (variance weighted): -0.0023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.9819\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9746\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1630\n",
      "  Median Pearson Correlation: 0.1626\n",
      "  R2 Score (uniform avg): 0.0238\n",
      "  R2 Score (variance weighted): 0.0238\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0023\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0439\n",
      "  Median Pearson Correlation: 0.0436\n",
      "  R2 Score (uniform avg): -0.0031\n",
      "  R2 Score (variance weighted): -0.0031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.9791\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9720\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1696\n",
      "  Median Pearson Correlation: 0.1691\n",
      "  R2 Score (uniform avg): 0.0264\n",
      "  R2 Score (variance weighted): 0.0264\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0030\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0464\n",
      "  Median Pearson Correlation: 0.0468\n",
      "  R2 Score (uniform avg): -0.0038\n",
      "  R2 Score (variance weighted): -0.0038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.9770\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9700\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1746\n",
      "  Median Pearson Correlation: 0.1739\n",
      "  R2 Score (uniform avg): 0.0284\n",
      "  R2 Score (variance weighted): 0.0284\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0036\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0488\n",
      "  Median Pearson Correlation: 0.0488\n",
      "  R2 Score (uniform avg): -0.0044\n",
      "  R2 Score (variance weighted): -0.0044\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.9753\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9684\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1788\n",
      "  Median Pearson Correlation: 0.1781\n",
      "  R2 Score (uniform avg): 0.0301\n",
      "  R2 Score (variance weighted): 0.0301\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0041\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0505\n",
      "  Median Pearson Correlation: 0.0513\n",
      "  R2 Score (uniform avg): -0.0049\n",
      "  R2 Score (variance weighted): -0.0049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.9738\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9670\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1820\n",
      "  Median Pearson Correlation: 0.1813\n",
      "  R2 Score (uniform avg): 0.0315\n",
      "  R2 Score (variance weighted): 0.0315\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0049\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0516\n",
      "  Median Pearson Correlation: 0.0525\n",
      "  R2 Score (uniform avg): -0.0057\n",
      "  R2 Score (variance weighted): -0.0057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.9726\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9659\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1842\n",
      "  Median Pearson Correlation: 0.1837\n",
      "  R2 Score (uniform avg): 0.0325\n",
      "  R2 Score (variance weighted): 0.0325\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0057\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0522\n",
      "  Median Pearson Correlation: 0.0526\n",
      "  R2 Score (uniform avg): -0.0065\n",
      "  R2 Score (variance weighted): -0.0065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.9717\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9649\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1866\n",
      "  Median Pearson Correlation: 0.1859\n",
      "  R2 Score (uniform avg): 0.0336\n",
      "  R2 Score (variance weighted): 0.0336\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0062\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0533\n",
      "  Median Pearson Correlation: 0.0527\n",
      "  R2 Score (uniform avg): -0.0070\n",
      "  R2 Score (variance weighted): -0.0070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 0.9707\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9641\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1882\n",
      "  Median Pearson Correlation: 0.1874\n",
      "  R2 Score (uniform avg): 0.0343\n",
      "  R2 Score (variance weighted): 0.0343\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0071\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0531\n",
      "  Median Pearson Correlation: 0.0523\n",
      "  R2 Score (uniform avg): -0.0079\n",
      "  R2 Score (variance weighted): -0.0079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 0.9701\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9634\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1894\n",
      "  Median Pearson Correlation: 0.1888\n",
      "  R2 Score (uniform avg): 0.0350\n",
      "  R2 Score (variance weighted): 0.0350\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0077\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0543\n",
      "  Median Pearson Correlation: 0.0539\n",
      "  R2 Score (uniform avg): -0.0085\n",
      "  R2 Score (variance weighted): -0.0084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 0.9694\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9630\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1904\n",
      "  Median Pearson Correlation: 0.1896\n",
      "  R2 Score (uniform avg): 0.0355\n",
      "  R2 Score (variance weighted): 0.0355\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0082\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0550\n",
      "  Median Pearson Correlation: 0.0556\n",
      "  R2 Score (uniform avg): -0.0090\n",
      "  R2 Score (variance weighted): -0.0090\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 0.9689\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9624\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1916\n",
      "  Median Pearson Correlation: 0.1908\n",
      "  R2 Score (uniform avg): 0.0360\n",
      "  R2 Score (variance weighted): 0.0360\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0088\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0548\n",
      "  Median Pearson Correlation: 0.0543\n",
      "  R2 Score (uniform avg): -0.0096\n",
      "  R2 Score (variance weighted): -0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 0.9684\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9620\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1925\n",
      "  Median Pearson Correlation: 0.1919\n",
      "  R2 Score (uniform avg): 0.0365\n",
      "  R2 Score (variance weighted): 0.0365\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0092\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0551\n",
      "  Median Pearson Correlation: 0.0549\n",
      "  R2 Score (uniform avg): -0.0100\n",
      "  R2 Score (variance weighted): -0.0100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 0.9680\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9617\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1931\n",
      "  Median Pearson Correlation: 0.1924\n",
      "  R2 Score (uniform avg): 0.0368\n",
      "  R2 Score (variance weighted): 0.0368\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0096\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0558\n",
      "  Median Pearson Correlation: 0.0567\n",
      "  R2 Score (uniform avg): -0.0104\n",
      "  R2 Score (variance weighted): -0.0104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 0.9677\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9613\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1938\n",
      "  Median Pearson Correlation: 0.1931\n",
      "  R2 Score (uniform avg): 0.0371\n",
      "  R2 Score (variance weighted): 0.0371\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0098\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0562\n",
      "  Median Pearson Correlation: 0.0557\n",
      "  R2 Score (uniform avg): -0.0106\n",
      "  R2 Score (variance weighted): -0.0106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 0.9673\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9611\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1943\n",
      "  Median Pearson Correlation: 0.1936\n",
      "  R2 Score (uniform avg): 0.0374\n",
      "  R2 Score (variance weighted): 0.0374\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0104\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0561\n",
      "  Median Pearson Correlation: 0.0567\n",
      "  R2 Score (uniform avg): -0.0111\n",
      "  R2 Score (variance weighted): -0.0111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 0.9670\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9608\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1948\n",
      "  Median Pearson Correlation: 0.1942\n",
      "  R2 Score (uniform avg): 0.0376\n",
      "  R2 Score (variance weighted): 0.0376\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0108\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0557\n",
      "  Median Pearson Correlation: 0.0554\n",
      "  R2 Score (uniform avg): -0.0115\n",
      "  R2 Score (variance weighted): -0.0115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 0.9668\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9606\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1953\n",
      "  Median Pearson Correlation: 0.1946\n",
      "  R2 Score (uniform avg): 0.0378\n",
      "  R2 Score (variance weighted): 0.0378\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0111\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0561\n",
      "  Median Pearson Correlation: 0.0555\n",
      "  R2 Score (uniform avg): -0.0119\n",
      "  R2 Score (variance weighted): -0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 0.9665\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9604\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1956\n",
      "  Median Pearson Correlation: 0.1949\n",
      "  R2 Score (uniform avg): 0.0380\n",
      "  R2 Score (variance weighted): 0.0380\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0115\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0558\n",
      "  Median Pearson Correlation: 0.0560\n",
      "  R2 Score (uniform avg): -0.0123\n",
      "  R2 Score (variance weighted): -0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 0.9664\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9603\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1960\n",
      "  Median Pearson Correlation: 0.1953\n",
      "  R2 Score (uniform avg): 0.0382\n",
      "  R2 Score (variance weighted): 0.0382\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0115\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0567\n",
      "  Median Pearson Correlation: 0.0562\n",
      "  R2 Score (uniform avg): -0.0123\n",
      "  R2 Score (variance weighted): -0.0123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 0.9662\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9601\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1962\n",
      "  Median Pearson Correlation: 0.1954\n",
      "  R2 Score (uniform avg): 0.0383\n",
      "  R2 Score (variance weighted): 0.0383\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0119\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0562\n",
      "  Median Pearson Correlation: 0.0553\n",
      "  R2 Score (uniform avg): -0.0127\n",
      "  R2 Score (variance weighted): -0.0127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 0.9661\n",
      "> Evaluation on train\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (27454, 1000), Prediction shape: (27454, 1000)\n",
      "  MSE: 0.9600\n",
      "  Avg Pearson Correlation (across features/voxels): 0.1965\n",
      "  Median Pearson Correlation: 0.1957\n",
      "  R2 Score (uniform avg): 0.0384\n",
      "  R2 Score (variance weighted): 0.0384\n",
      "\n",
      "> Evaluation on test\n",
      "Evaluating encoding model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation complete. Target shape: (2968, 1000), Prediction shape: (2968, 1000)\n",
      "  MSE: 1.0121\n",
      "  Avg Pearson Correlation (across features/voxels): 0.0566\n",
      "  Median Pearson Correlation: 0.0560\n",
      "  R2 Score (uniform avg): -0.0129\n",
      "  R2 Score (variance weighted): -0.0129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training (encoding):  95%|| 406/429 [02:09<00:07,  3.18it/s, loss=0.947]"
     ]
    }
   ],
   "source": [
    "encoding_model = run_training_no_val( # Use modified training loop\n",
    "    encoding_model, train_loader, device=DEVICE, task='encoding',\n",
    "    epochs=EPOCHS, learning_rate=LEARNING_RATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if test_loader:\n",
    "#     print(f\"\\n--- Evaluating Encoding Model on Subj {TEST_SUBJECT_ID} ---\")\n",
    "#     enc_results, enc_targets, enc_predictions = evaluate_model(\n",
    "#             encoding_model, test_loader, nn.MSELoss(), device=DEVICE, task='encoding'\n",
    "#     )\n",
    "#     # --- Add encoder/subject info to output files ---\n",
    "#     enc_model_suffix = f\"_mlp_{chosen_encoder}_train{''.join(TRAIN_SUBJECT_IDS)}_test{TEST_SUBJECT_ID}\"\n",
    "#     enc_model_path = OUTPUT_DIR / f\"encoding_model{enc_model_suffix}.pt\"\n",
    "#     torch.save(encoding_model.state_dict(), enc_model_path)\n",
    "#     print(f\"Saved Encoding model to {enc_model_path}\")\n",
    "\n",
    "#     enc_fig = plot_predictions(enc_targets, enc_predictions, n_samples=5, title=f\"Encoding (MLP, {chosen_encoder}) Test Subj {TEST_SUBJECT_ID}\")\n",
    "#     enc_plot_path = OUTPUT_DIR / f\"encoding_predictions{enc_model_suffix}.png\"\n",
    "#     enc_fig.savefig(enc_plot_path)\n",
    "#     plt.close(enc_fig)\n",
    "#     print(f\"Saved Encoding prediction plot to {enc_plot_path}\")\n",
    "    \n",
    "# else:\n",
    "#         print(\"Skipping encoding model evaluation as no test loader was created.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### --- Decoding Model Training & Evaluation ---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f\"\\n--- Training Decoding Model (MLP, Video: {chosen_encoder}) on Subj {TRAIN_SUBJECT_IDS} ---\")\n",
    "# if DEVICE == 'cuda' or 'cuda:0' or 'cuda:2':\n",
    "#     # Clear memory if possible\n",
    "#     del encoding_model\n",
    "#     if 'enc_targets' in locals(): del enc_targets\n",
    "#     if 'enc_predictions' in locals(): del enc_predictions\n",
    "#     torch.cuda.empty_cache()\n",
    "#     print(\"Cleared CUDA cache before starting decoding model training.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoding_model = run_training_no_val( # Use modified training loop\n",
    "#     decoding_model, train_loader, device=DEVICE, task='decoding',\n",
    "#     epochs=EPOCHS, learning_rate=LEARNING_RATE\n",
    "# )\n",
    "\n",
    "# if test_loader:\n",
    "#     print(f\"\\n--- Evaluating Decoding Model on Subj {TEST_SUBJECT_ID} ---\")\n",
    "#     dec_results, dec_targets, dec_predictions = evaluate_model(\n",
    "#         decoding_model, test_loader, nn.MSELoss(), device=DEVICE, task='decoding'\n",
    "#     )\n",
    "#     dec_model_suffix = f\"_mlp_{chosen_encoder}_train{''.join(TRAIN_SUBJECT_IDS)}_test{TEST_SUBJECT_ID}\"\n",
    "#     dec_model_path = OUTPUT_DIR / f\"decoding_model{dec_model_suffix}.pt\"\n",
    "#     # torch.save(decoding_model.state_dict(), dec_model_path)\n",
    "#     print(f\"Saved Decoding model to {dec_model_path}\")\n",
    "\n",
    "#     dec_fig = plot_predictions(dec_targets, dec_predictions, n_samples=5, title=f\"Decoding (MLP, {chosen_encoder}) Test Subj {TEST_SUBJECT_ID}\")\n",
    "#     dec_plot_path = OUTPUT_DIR / f\"decoding_predictions{dec_model_suffix}.png\"\n",
    "#     # dec_fig.savefig(dec_plot_path)\n",
    "#     plt.close(dec_fig)\n",
    "#     print(f\"Saved Decoding prediction plot to {dec_plot_path}\")\n",
    "# else:\n",
    "#         print(\"Skipping decoding model evaluation as no test loader was created.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
